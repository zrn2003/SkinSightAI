{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SkinSight: Stage 1 - Filter Model Training\n",
    "\n",
    "This notebook trains the **Filter Model** (Binary Classifier: Skin vs Random).\n",
    "Its purpose is to filter out non-skin images before they reach the diagnostic model.\n",
    "\n",
    "**Classes**:\n",
    "0: Random Object\n",
    "1: Skin (Melanoma + Tinea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 1. Dependencies\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Configuration\n",
    "DATASET_DIR = 'Dataset'\n",
    "CACHE_DIR = 'Dataset_Cache_Filter' # Separate cache for safety\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preprocessing (Optimized with Caching)\n",
    "class AdvancedPreprocessing:\n",
    "    @staticmethod\n",
    "    def hair_removal(image_np):\n",
    "        gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (17, 17))\n",
    "        blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "        _, mask = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
    "        return cv2.inpaint(image_np, mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_clahe(image_np):\n",
    "        lab = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        l = clahe.apply(l)\n",
    "        return cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    @staticmethod\n",
    "    def shades_of_grey(image_np, power=6):\n",
    "        img_dtype = image_np.dtype\n",
    "        r_norm = np.power(np.mean(np.power(image_np[:,:,0], power)), 1/power)\n",
    "        g_norm = np.power(np.mean(np.power(image_np[:,:,1], power)), 1/power)\n",
    "        b_norm = np.power(np.mean(np.power(image_np[:,:,2], power)), 1/power)\n",
    "        norm_vec = np.array([r_norm, g_norm, b_norm])\n",
    "        norm_vec = norm_vec / (np.sqrt(np.sum(np.square(norm_vec))) + 1e-6)\n",
    "        uniform_illum = 1 / np.sqrt(3)\n",
    "        manul_wb = np.diag([uniform_illum]*3) / (np.diag(norm_vec) + 1e-6)\n",
    "        corrected = np.dot(image_np, manul_wb)\n",
    "        return np.clip(corrected, 0, 255).astype(img_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Dataset Class (Filter Mode)\n",
    "class SkinFilterDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.resize = transforms.Resize((224, 224))\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        # Ensure Cache Directory\n",
    "        os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Caching Logic\n",
    "        filename_id = f\"{os.path.basename(os.path.dirname(img_path))}_{os.path.basename(img_path)}\"\n",
    "        cache_path = os.path.join(CACHE_DIR, filename_id)\n",
    "        \n",
    "        image = None\n",
    "        if os.path.exists(cache_path):\n",
    "            try:\n",
    "                image = cv2.imread(cache_path)\n",
    "                if image is not None:\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if image is None:\n",
    "            try:\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # Apply preprocessing\n",
    "                image = AdvancedPreprocessing.hair_removal(image)\n",
    "                image = AdvancedPreprocessing.apply_clahe(image)\n",
    "                image = AdvancedPreprocessing.shades_of_grey(image)\n",
    "                # Save cache\n",
    "                cv2.imwrite(cache_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "\n",
    "        image_pil = Image.fromarray(image)\n",
    "        x = self.resize(image_pil)\n",
    "        x = self.to_tensor(x)\n",
    "        x = self.normalize(x)\n",
    "        return x, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4375 | Val: 547\n"
     ]
    }
   ],
   "source": [
    "# 5. Data Preparation\n",
    "def prepare_filter_data(dataset_dir):\n",
    "    melanoma = [os.path.join(dataset_dir, 'Melanoma', f) for f in os.listdir(os.path.join(dataset_dir, 'Melanoma'))]\n",
    "    tinea = [os.path.join(dataset_dir, 'Tinea', f) for f in os.listdir(os.path.join(dataset_dir, 'Tinea'))]\n",
    "    \n",
    "    random_path = os.path.join(dataset_dir, 'random')\n",
    "    if not os.path.exists(random_path): random_path = os.path.join(dataset_dir, 'Random_Obj')\n",
    "    random_files = [os.path.join(random_path, f) for f in os.listdir(random_path)]\n",
    "    \n",
    "    # Class 0: Random, Class 1: Skin\n",
    "    files = random_files + melanoma + tinea\n",
    "    labels = [0]*len(random_files) + [1]*(len(melanoma) + len(tinea))\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(files, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "    \n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "def get_weighted_sampler(labels):\n",
    "    counts = np.bincount(labels)\n",
    "    weights = 1. / counts\n",
    "    sample_weights = [weights[l] for l in labels]\n",
    "    return WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "(train_X, train_y), (val_X, val_y), (test_X, test_y) = prepare_filter_data(DATASET_DIR)\n",
    "\n",
    "train_ds = SkinFilterDataset(train_X, train_y)\n",
    "val_ds = SkinFilterDataset(val_X, val_y)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=get_weighted_sampler(train_y), drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "print(f\"Train: {len(train_ds)} | Val: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Definition (ResNet18)\n",
    "class FilterModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FilterModel, self).__init__()\n",
    "        self.model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 2) \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = FilterModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████████████████████████████████████████████████████| 273/273 [09:35<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1396 | Val Acc: 98.35%\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████████████████████████████████████████████████████| 273/273 [07:16<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0914 | Val Acc: 98.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████████████████████████████████████████████████████| 273/273 [06:44<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0691 | Val Acc: 95.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████████████████████████████████████████████████████| 273/273 [06:12<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0604 | Val Acc: 96.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████████████████████████████████████████████████████| 273/273 [05:46<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0318 | Val Acc: 98.53%\n",
      "Model Saved!\n",
      "Filter Model Training Completed.\n"
     ]
    }
   ],
   "source": [
    "# 7. Training Loop\n",
    "os.makedirs('models', exist_ok=True)\n",
    "best_acc = 0.0\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            \n",
    "    val_acc = 100 * correct / total\n",
    "    print(f\"Loss: {running_loss/len(train_loader):.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'models/filter_model.pth')\n",
    "        print(\"Model Saved!\")\n",
    "\n",
    "print(\"Filter Model Training Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
